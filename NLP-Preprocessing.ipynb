{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54e5d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, WhitespaceTokenizer # 1. Tokenization\n",
    "from string import punctuation                                              # 3. remove punctuations\n",
    "from nltk.corpus import stopwords                                           # 4. remove stopwords\n",
    "import contractions                                                         # 5. contraction mapping\n",
    "from nltk.stem import WordNetLemmatizer, LancasterStemmer                   # 6. Stemming and Lematization\n",
    "from unidecode import unidecode                                             # 7. handling accented character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "109b0706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd7988d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "700fe4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bceaee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"The Moon is a barren, rocky world without air and water. \n",
    "It has dark lava plain on its surface. The Moon is filled wit craters. \n",
    "It has no light of its own. It gets its light from the Sun. The Moo keeps changing its\n",
    "shape as it moves round the Earth. It spins on its axis in 27.3 days stars were named after\n",
    "the Edwin Aldrin were the first ones to set their foot on the Moon on 21 \n",
    "July 1969 They reached the Moon in their space craft named Apollo II.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a701ab30",
   "metadata": {},
   "source": [
    "## Preprocessing Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05669584",
   "metadata": {},
   "source": [
    "### 1. Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f37a7a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Moon is a barren, rocky world without air and water.',\n",
       " 'It has dark lava plain on its surface.',\n",
       " 'The Moon is filled wit craters.',\n",
       " 'It has no light of its own.',\n",
       " 'It gets its light from the Sun.',\n",
       " 'The Moo keeps changing its\\nshape as it moves round the Earth.',\n",
       " 'It spins on its axis in 27.3 days stars were named after\\nthe Edwin Aldrin were the first ones to set their foot on the Moon on 21 \\nJuly 1969 They reached the Moon in their space craft named Apollo II.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence tokenization\n",
    "tokens_sent = sent_tokenize(text)\n",
    "tokens_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a9fe3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Moon',\n",
       " 'is',\n",
       " 'a',\n",
       " 'barren',\n",
       " ',',\n",
       " 'rocky',\n",
       " 'world',\n",
       " 'without',\n",
       " 'air',\n",
       " 'and',\n",
       " 'water',\n",
       " '.',\n",
       " 'It',\n",
       " 'has',\n",
       " 'dark',\n",
       " 'lava',\n",
       " 'plain',\n",
       " 'on',\n",
       " 'its',\n",
       " 'surface',\n",
       " '.',\n",
       " 'The',\n",
       " 'Moon',\n",
       " 'is',\n",
       " 'filled',\n",
       " 'wit',\n",
       " 'craters',\n",
       " '.',\n",
       " 'It',\n",
       " 'has',\n",
       " 'no',\n",
       " 'light',\n",
       " 'of',\n",
       " 'its',\n",
       " 'own',\n",
       " '.',\n",
       " 'It',\n",
       " 'gets',\n",
       " 'its',\n",
       " 'light',\n",
       " 'from',\n",
       " 'the',\n",
       " 'Sun',\n",
       " '.',\n",
       " 'The',\n",
       " 'Moo',\n",
       " 'keeps',\n",
       " 'changing',\n",
       " 'its',\n",
       " 'shape',\n",
       " 'as',\n",
       " 'it',\n",
       " 'moves',\n",
       " 'round',\n",
       " 'the',\n",
       " 'Earth',\n",
       " '.',\n",
       " 'It',\n",
       " 'spins',\n",
       " 'on',\n",
       " 'its',\n",
       " 'axis',\n",
       " 'in',\n",
       " '27.3',\n",
       " 'days',\n",
       " 'stars',\n",
       " 'were',\n",
       " 'named',\n",
       " 'after',\n",
       " 'the',\n",
       " 'Edwin',\n",
       " 'Aldrin',\n",
       " 'were',\n",
       " 'the',\n",
       " 'first',\n",
       " 'ones',\n",
       " 'to',\n",
       " 'set',\n",
       " 'their',\n",
       " 'foot',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Moon',\n",
       " 'on',\n",
       " '21',\n",
       " 'July',\n",
       " '1969',\n",
       " 'They',\n",
       " 'reached',\n",
       " 'the',\n",
       " 'Moon',\n",
       " 'in',\n",
       " 'their',\n",
       " 'space',\n",
       " 'craft',\n",
       " 'named',\n",
       " 'Apollo',\n",
       " 'II',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word tokenization\n",
    "text1 = 'The Moon is a barren, rocky world without air and water.'\n",
    "token_words = word_tokenize(text)\n",
    "token_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d12c7b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Moon',\n",
       " 'is',\n",
       " 'a',\n",
       " 'barren,',\n",
       " 'rocky',\n",
       " 'world',\n",
       " 'without',\n",
       " 'air',\n",
       " 'and',\n",
       " 'water.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Whitespace Tokenizer - working just like .split with spaces\n",
    "ws_tokens = WhitespaceTokenizer().tokenize(text1)\n",
    "ws_tokens\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be542ec9",
   "metadata": {},
   "source": [
    "Difference between Word Tokenization and Whitespace Tokenizer\n",
    "1. Word Tokenization consider punctuations as token.\n",
    "2. Whitespace Tokenizer consider punctuation as a token only if contains space in between."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fdc10b",
   "metadata": {},
   "source": [
    "### 2. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "031753db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'moon',\n",
       " 'is',\n",
       " 'a',\n",
       " 'barren',\n",
       " ',',\n",
       " 'rocky',\n",
       " 'world',\n",
       " 'without',\n",
       " 'air',\n",
       " 'and',\n",
       " 'water',\n",
       " '.',\n",
       " 'it',\n",
       " 'has',\n",
       " 'dark',\n",
       " 'lava',\n",
       " 'plain',\n",
       " 'on',\n",
       " 'its',\n",
       " 'surface',\n",
       " '.',\n",
       " 'the',\n",
       " 'moon',\n",
       " 'is',\n",
       " 'filled',\n",
       " 'wit',\n",
       " 'craters',\n",
       " '.',\n",
       " 'it',\n",
       " 'has',\n",
       " 'no',\n",
       " 'light',\n",
       " 'of',\n",
       " 'its',\n",
       " 'own',\n",
       " '.',\n",
       " 'it',\n",
       " 'gets',\n",
       " 'its',\n",
       " 'light',\n",
       " 'from',\n",
       " 'the',\n",
       " 'sun',\n",
       " '.',\n",
       " 'the',\n",
       " 'moo',\n",
       " 'keeps',\n",
       " 'changing',\n",
       " 'its',\n",
       " 'shape',\n",
       " 'as',\n",
       " 'it',\n",
       " 'moves',\n",
       " 'round',\n",
       " 'the',\n",
       " 'earth',\n",
       " '.',\n",
       " 'it',\n",
       " 'spins',\n",
       " 'on',\n",
       " 'its',\n",
       " 'axis',\n",
       " 'in',\n",
       " '27.3',\n",
       " 'days',\n",
       " 'stars',\n",
       " 'were',\n",
       " 'named',\n",
       " 'after',\n",
       " 'the',\n",
       " 'edwin',\n",
       " 'aldrin',\n",
       " 'were',\n",
       " 'the',\n",
       " 'first',\n",
       " 'ones',\n",
       " 'to',\n",
       " 'set',\n",
       " 'their',\n",
       " 'foot',\n",
       " 'on',\n",
       " 'the',\n",
       " 'moon',\n",
       " 'on',\n",
       " '21',\n",
       " 'july',\n",
       " '1969',\n",
       " 'they',\n",
       " 'reached',\n",
       " 'the',\n",
       " 'moon',\n",
       " 'in',\n",
       " 'their',\n",
       " 'space',\n",
       " 'craft',\n",
       " 'named',\n",
       " 'apollo',\n",
       " 'ii',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_lower_text = [i.lower() for i in token_words]\n",
    "token_lower_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abe0b69",
   "metadata": {},
   "source": [
    "### 3. Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c27a7251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42b0026f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'moon',\n",
       " 'is',\n",
       " 'a',\n",
       " 'barren',\n",
       " 'rocky',\n",
       " 'world',\n",
       " 'without',\n",
       " 'air',\n",
       " 'and',\n",
       " 'water',\n",
       " 'it',\n",
       " 'has',\n",
       " 'dark',\n",
       " 'lava',\n",
       " 'plain',\n",
       " 'on',\n",
       " 'its',\n",
       " 'surface',\n",
       " 'the',\n",
       " 'moon',\n",
       " 'is',\n",
       " 'filled',\n",
       " 'wit',\n",
       " 'craters',\n",
       " 'it',\n",
       " 'has',\n",
       " 'no',\n",
       " 'light',\n",
       " 'of',\n",
       " 'its',\n",
       " 'own',\n",
       " 'it',\n",
       " 'gets',\n",
       " 'its',\n",
       " 'light',\n",
       " 'from',\n",
       " 'the',\n",
       " 'sun',\n",
       " 'the',\n",
       " 'moo',\n",
       " 'keeps',\n",
       " 'changing',\n",
       " 'its',\n",
       " 'shape',\n",
       " 'as',\n",
       " 'it',\n",
       " 'moves',\n",
       " 'round',\n",
       " 'the',\n",
       " 'earth',\n",
       " 'it',\n",
       " 'spins',\n",
       " 'on',\n",
       " 'its',\n",
       " 'axis',\n",
       " 'in',\n",
       " '27.3',\n",
       " 'days',\n",
       " 'stars',\n",
       " 'were',\n",
       " 'named',\n",
       " 'after',\n",
       " 'the',\n",
       " 'edwin',\n",
       " 'aldrin',\n",
       " 'were',\n",
       " 'the',\n",
       " 'first',\n",
       " 'ones',\n",
       " 'to',\n",
       " 'set',\n",
       " 'their',\n",
       " 'foot',\n",
       " 'on',\n",
       " 'the',\n",
       " 'moon',\n",
       " 'on',\n",
       " '21',\n",
       " 'july',\n",
       " '1969',\n",
       " 'they',\n",
       " 'reached',\n",
       " 'the',\n",
       " 'moon',\n",
       " 'in',\n",
       " 'their',\n",
       " 'space',\n",
       " 'craft',\n",
       " 'named',\n",
       " 'apollo',\n",
       " 'ii']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_without_punc = [i for i in token_lower_text if i not in punctuation]\n",
    "tokens_without_punc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3cb749",
   "metadata": {},
   "source": [
    "### 4. Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fa6fffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cc9680f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['moon',\n",
       " 'barren',\n",
       " 'rocky',\n",
       " 'world',\n",
       " 'without',\n",
       " 'air',\n",
       " 'water',\n",
       " 'dark',\n",
       " 'lava',\n",
       " 'plain',\n",
       " 'surface',\n",
       " 'moon',\n",
       " 'filled',\n",
       " 'wit',\n",
       " 'craters',\n",
       " 'light',\n",
       " 'gets',\n",
       " 'light',\n",
       " 'sun',\n",
       " 'moo',\n",
       " 'keeps',\n",
       " 'changing',\n",
       " 'shape',\n",
       " 'moves',\n",
       " 'round',\n",
       " 'earth',\n",
       " 'spins',\n",
       " 'axis',\n",
       " '27.3',\n",
       " 'days',\n",
       " 'stars',\n",
       " 'named',\n",
       " 'edwin',\n",
       " 'aldrin',\n",
       " 'first',\n",
       " 'ones',\n",
       " 'set',\n",
       " 'foot',\n",
       " 'moon',\n",
       " '21',\n",
       " 'july',\n",
       " '1969',\n",
       " 'reached',\n",
       " 'moon',\n",
       " 'space',\n",
       " 'craft',\n",
       " 'named',\n",
       " 'apollo',\n",
       " 'ii']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_without_stopwords = [i for i in tokens_without_punc if i not in stop_words]\n",
    "token_without_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d71c1d",
   "metadata": {},
   "source": [
    "### 5. Contraction Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1dc048c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I did not like the movie'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"I didn't like the movie\"\n",
    "expanded_text = contractions.fix(text1)\n",
    "expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adf4195b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I cannot like the movie'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"I can't like the movie\"\n",
    "expanded_text = contractions.fix(text1)\n",
    "expanded_text"
   ]
  },
  {
   "cell_type": "raw",
   "id": "28a483e8",
   "metadata": {},
   "source": [
    "{can't : can not}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd73a9d2",
   "metadata": {},
   "source": [
    "### 6. Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6207d839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word : moon\n",
      "Stem word : moon\n",
      "Lemma word : moon\n",
      "**************************************************\n",
      "word : barren\n",
      "Stem word : bar\n",
      "Lemma word : barren\n",
      "**************************************************\n",
      "word : rocky\n",
      "Stem word : rocky\n",
      "Lemma word : rocky\n",
      "**************************************************\n",
      "word : world\n",
      "Stem word : world\n",
      "Lemma word : world\n",
      "**************************************************\n",
      "word : without\n",
      "Stem word : without\n",
      "Lemma word : without\n",
      "**************************************************\n",
      "word : air\n",
      "Stem word : air\n",
      "Lemma word : air\n",
      "**************************************************\n",
      "word : water\n",
      "Stem word : wat\n",
      "Lemma word : water\n",
      "**************************************************\n",
      "word : dark\n",
      "Stem word : dark\n",
      "Lemma word : dark\n",
      "**************************************************\n",
      "word : lava\n",
      "Stem word : lav\n",
      "Lemma word : lava\n",
      "**************************************************\n",
      "word : plain\n",
      "Stem word : plain\n",
      "Lemma word : plain\n",
      "**************************************************\n",
      "word : surface\n",
      "Stem word : surfac\n",
      "Lemma word : surface\n",
      "**************************************************\n",
      "word : moon\n",
      "Stem word : moon\n",
      "Lemma word : moon\n",
      "**************************************************\n",
      "word : filled\n",
      "Stem word : fil\n",
      "Lemma word : filled\n",
      "**************************************************\n",
      "word : wit\n",
      "Stem word : wit\n",
      "Lemma word : wit\n",
      "**************************************************\n",
      "word : craters\n",
      "Stem word : crat\n",
      "Lemma word : crater\n",
      "**************************************************\n",
      "word : light\n",
      "Stem word : light\n",
      "Lemma word : light\n",
      "**************************************************\n",
      "word : gets\n",
      "Stem word : get\n",
      "Lemma word : get\n",
      "**************************************************\n",
      "word : light\n",
      "Stem word : light\n",
      "Lemma word : light\n",
      "**************************************************\n",
      "word : sun\n",
      "Stem word : sun\n",
      "Lemma word : sun\n",
      "**************************************************\n",
      "word : moo\n",
      "Stem word : moo\n",
      "Lemma word : moo\n",
      "**************************************************\n",
      "word : keeps\n",
      "Stem word : keep\n",
      "Lemma word : keep\n",
      "**************************************************\n",
      "word : changing\n",
      "Stem word : chang\n",
      "Lemma word : changing\n",
      "**************************************************\n",
      "word : shape\n",
      "Stem word : shap\n",
      "Lemma word : shape\n",
      "**************************************************\n",
      "word : moves\n",
      "Stem word : mov\n",
      "Lemma word : move\n",
      "**************************************************\n",
      "word : round\n",
      "Stem word : round\n",
      "Lemma word : round\n",
      "**************************************************\n",
      "word : earth\n",
      "Stem word : ear\n",
      "Lemma word : earth\n",
      "**************************************************\n",
      "word : spins\n",
      "Stem word : spin\n",
      "Lemma word : spin\n",
      "**************************************************\n",
      "word : axis\n",
      "Stem word : ax\n",
      "Lemma word : axis\n",
      "**************************************************\n",
      "word : 27.3\n",
      "Stem word : 27.3\n",
      "Lemma word : 27.3\n",
      "**************************************************\n",
      "word : days\n",
      "Stem word : day\n",
      "Lemma word : day\n",
      "**************************************************\n",
      "word : stars\n",
      "Stem word : star\n",
      "Lemma word : star\n",
      "**************************************************\n",
      "word : named\n",
      "Stem word : nam\n",
      "Lemma word : named\n",
      "**************************************************\n",
      "word : edwin\n",
      "Stem word : edwin\n",
      "Lemma word : edwin\n",
      "**************************************************\n",
      "word : aldrin\n",
      "Stem word : aldrin\n",
      "Lemma word : aldrin\n",
      "**************************************************\n",
      "word : first\n",
      "Stem word : first\n",
      "Lemma word : first\n",
      "**************************************************\n",
      "word : ones\n",
      "Stem word : on\n",
      "Lemma word : one\n",
      "**************************************************\n",
      "word : set\n",
      "Stem word : set\n",
      "Lemma word : set\n",
      "**************************************************\n",
      "word : foot\n",
      "Stem word : foot\n",
      "Lemma word : foot\n",
      "**************************************************\n",
      "word : moon\n",
      "Stem word : moon\n",
      "Lemma word : moon\n",
      "**************************************************\n",
      "word : 21\n",
      "Stem word : 21\n",
      "Lemma word : 21\n",
      "**************************************************\n",
      "word : july\n",
      "Stem word : july\n",
      "Lemma word : july\n",
      "**************************************************\n",
      "word : 1969\n",
      "Stem word : 1969\n",
      "Lemma word : 1969\n",
      "**************************************************\n",
      "word : reached\n",
      "Stem word : reach\n",
      "Lemma word : reached\n",
      "**************************************************\n",
      "word : moon\n",
      "Stem word : moon\n",
      "Lemma word : moon\n",
      "**************************************************\n",
      "word : space\n",
      "Stem word : spac\n",
      "Lemma word : space\n",
      "**************************************************\n",
      "word : craft\n",
      "Stem word : craft\n",
      "Lemma word : craft\n",
      "**************************************************\n",
      "word : named\n",
      "Stem word : nam\n",
      "Lemma word : named\n",
      "**************************************************\n",
      "word : apollo\n",
      "Stem word : apollo\n",
      "Lemma word : apollo\n",
      "**************************************************\n",
      "word : ii\n",
      "Stem word : ii\n",
      "Lemma word : ii\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "stemming = LancasterStemmer()\n",
    "lemma = WordNetLemmatizer()\n",
    "for word in token_without_stopwords:\n",
    "    stem_word = stemming.stem(word)\n",
    "    lemma_word = lemma.lemmatize(word)\n",
    "    print(f'word : {word}')\n",
    "    print(f'Stem word : {stem_word}')\n",
    "    print(f'Lemma word : {lemma_word}')\n",
    "    print('*'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2f6de4",
   "metadata": {},
   "source": [
    "### 7. Accented Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd4d2ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a, A, a, e, E'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accented_character = 'á, Á, å, é, É'\n",
    "fixed_words = unidecode(accented_character)\n",
    "fixed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7018e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
